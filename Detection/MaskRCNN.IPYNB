{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled","provenance":[],"collapsed_sections":[],"mount_file_id":"1DCQVRIhcQfIGBcSEbo42kVAddBQ5Rx0b","authorship_tag":"ABX9TyOG8IOsQtye79nDMSikoiBI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uo34eHo7LDKz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594198050161,"user_tz":-300,"elapsed":157110,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"5052c8a3-658d-4342-9123-5ac51d1a81a2"},"source":["# install dependencies: (use cu101 because colab has CUDA 10.1)\n","!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n","Collecting torch==1.5\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n","\u001b[K     |████████████████████████████████| 703.8MB 26kB/s \n","\u001b[?25hCollecting torchvision==0.6\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n","\u001b[K     |████████████████████████████████| 6.6MB 17.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.5.1+cu101\n","    Uninstalling torch-1.5.1+cu101:\n","      Successfully uninstalled torch-1.5.1+cu101\n","  Found existing installation: torchvision 0.6.1+cu101\n","    Uninstalling torchvision-0.6.1+cu101:\n","      Successfully uninstalled torchvision-0.6.1+cu101\n","Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.20)\n","Collecting pyyaml==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 5.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=d32724a840312370bd0289aeb6051b605119290d1fc825739db90ba2b5ba9f88\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-n593axjl\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-n593axjl\n","Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (47.3.1)\n","Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.20)\n","Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266989 sha256=71be90b00be70771fb0a83a7d2389fcdb556ce053fbb80ecec48bc37fb24ecac\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-gxigri9c/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Found existing installation: pycocotools 2.0.1\n","    Uninstalling pycocotools-2.0.1:\n","      Successfully uninstalled pycocotools-2.0.1\n","Successfully installed pycocotools-2.0\n","1.5.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ipjWwD4x9pnx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594197816946,"user_tz":-300,"elapsed":56966,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"60644917-28b4-480f-a4ed-6337e02ea33b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vDiGPUttLF25","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594198058795,"user_tz":-300,"elapsed":162850,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"61ec197b-0520-4029-c083-60b2df714a5a"},"source":["# install detectron2:\n","!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n","Collecting detectron2==0.1.3\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.2MB)\n","\u001b[K     |████████████████████████████████| 6.2MB 659kB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n","Collecting fvcore>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/69/f0/dfee20a11c469e43061532e6e1467b9f3614dab10ad5a964e14f78f6631a/fvcore-0.1.1.post20200704.tar.gz\n","Collecting mock\n","  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.18.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.3) (5.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.10.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.6.0.post3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.12.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (47.3.1)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.6.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.1.post20200704-cp36-none-any.whl size=41894 sha256=c3a3dd8aee48f9823c282ba6e17890b3836709fe1ad9aa0dab470ae3b66bb559\n","  Stored in directory: /root/.cache/pip/wheels/fb/d2/8e/b6d0f19811e77dabff1ebed6605ce2b59ee9f487079b434c8c\n","Successfully built fvcore\n","Installing collected packages: yacs, portalocker, fvcore, mock, detectron2\n","Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.1.post20200704 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nnjr0GkWLG_4","colab_type":"code","colab":{}},"source":["# You may need to restart your runtime prior to this, to let your installation take effect\n","# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6tGqbpQLUsT","colab_type":"code","colab":{}},"source":["# !unzip '/content/drive/My Drive/new hope/train.zip'\n","# !unzip '/content/drive/My Drive/new hope/test.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABiDTmmvLS5u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594198206734,"user_tz":-300,"elapsed":1480,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"24a98699-e8bc-48e9-9ff7-b8aac981783a"},"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"cancer_train\", {}, \"/content/drive/My Drive/new hope/train.json\", \"/content/train\")\n","MetadataCatalog.get(\"cancer_train\").set(thing_classes=[\"tumor\"])\n","cancer_matadata = MetadataCatalog.get(\"cancer_train\")\n","print(cancer_matadata)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metadata(evaluator_type='coco', image_root='/content/train', json_file='/content/drive/My Drive/new hope/train.json', name='cancer_train', thing_classes=['tumor'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uY9IMpTjLWJ0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594198069992,"user_tz":-300,"elapsed":160197,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"99d03191-8da0-4ee0-a50b-3b17c7857354"},"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"cancer_test1\", {}, \"/content/drive/My Drive/new hope/test.json\", \"/content/test\")\n","MetadataCatalog.get(\"cancer_test1\").set(thing_classes=[\"tumor\"])\n","cancer_matadata = MetadataCatalog.get(\"cancer_test1\")\n","print(cancer_matadata)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metadata(evaluator_type='coco', image_root='/content/test', json_file='/content/drive/My Drive/new hope/test.json', name='cancer_test1', thing_classes=['tumor'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ogTQVVVpLXfC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594198229305,"user_tz":-300,"elapsed":22369,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"57e6fdc8-2dd5-409d-a79d-77fa04813a72"},"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","import os\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"cancer_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","# cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl.pkl\" # Let training initialize from model zoo\n","# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n","cfg.MODEL.WEIGHTS = '/content/drive/My Drive/new hope/model_0049999.pth'\n","cfg.SOLVER.IMS_PER_BATCH = 1\n","cfg.SOLVER.BASE_LR = 0.000025\n","cfg.SOLVER.MAX_ITER = 70000   \n","# cfg.INPUT.MIN_SIZE_TRAIN = (1500,1500)\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1024\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (cancer)\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=True)\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[07/08 08:50:10 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[07/08 08:50:10 d2.data.datasets.coco]: \u001b[0mLoaded 1315 images in COCO format from /content/drive/My Drive/new hope/train.json\n","\u001b[32m[07/08 08:50:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1315 images left.\n","\u001b[32m[07/08 08:50:10 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|   tumor    | 3214         |\n","|            |              |\u001b[0m\n","\u001b[32m[07/08 08:50:10 d2.data.common]: \u001b[0mSerializing 1315 elements to byte tensors and concatenating them all ...\n","\u001b[32m[07/08 08:50:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n","\u001b[32m[07/08 08:50:10 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[07/08 08:50:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8hjECubLZia","colab_type":"code","colab":{}},"source":["#10000 Iterations\n","cfg.MODEL.WEIGHTS = '/content/drive/My Drive/new hope/model_0049999.pth'\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2  # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"cancer_train\", )\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH31hPm8LghJ","colab_type":"code","colab":{}},"source":["'''\n","Finding True Positive, False Negative samples in train dataset.\n","'''\n","\n","\n","from detectron2.utils.visualizer import ColorMode\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","from detectron2.structures import BoxMode\n","import math  \n","import csv\n","from tqdm import tqdm\n","\n","dataset_dicts = DatasetCatalog.get(\"cancer_train\")\n","cancer_metadata = MetadataCatalog.get(\"cancer_train\")\n","\n","TP = 0\n","FN = 0\n","FP = 0\n","total = 0\n","true_count = 0\n","false_count = 0\n","\n","for d in tqdm(dataset_dicts): \n","\n","        bboxs = []\n","        bbox_center_x = []\n","        bbox_center_y = []\n","\n","        predicted_centers_x = []\n","        predicted_centers_y = []\n","\n","        im = cv2.imread(d['file_name'])\n","        outputs = predictor(im)\n","\n","        for i in range(len(d['annotations'])):\n","            bboxs.append(d['annotations'][i]['bbox'])\n","\n","        total = total + len(bboxs)\n","\n","        for bbox in bboxs:\n","            bbox_center_x.append((bbox[0]+bbox[0]+bbox[2])/2)\n","            bbox_center_y.append((bbox[1]+bbox[1]+bbox[3])/2)\n","\n","        predicted_bboxs = outputs[\"instances\"].pred_boxes.to(\"cpu\").tensor.numpy()\n","        \n","        for predicted_bbox in predicted_bboxs:\n","            predicted_centers_x.append((predicted_bbox[0]+predicted_bbox[2])/2)\n","            predicted_centers_y.append((predicted_bbox[1]+predicted_bbox[3])/2)  \n","\n","        i = 0\n","        while i < len(predicted_centers_x):\n","            j = 0\n","            while j < len(predicted_centers_x):\n","                if i == j:\n","                    j += 1\n","                    pass\n","                else:\n","                    if (math.sqrt( (predicted_centers_y[j] - predicted_centers_y[i])**2 + \n","                                        (predicted_centers_x[j] - predicted_centers_x[i])**2 ) ) <= 40:\n","\n","                        predicted_centers_x = np.delete(predicted_centers_x,j)\n","                        predicted_centers_y = np.delete(predicted_centers_y,j)\n","\n","                    else:\n","                        j += 1\n","\n","            i += 1\n","\n","        temp_bbox_x = bbox_center_x\n","        temp_bbox_y = bbox_center_y\n","\n","\n","        for m in range(len(predicted_centers_x)):\n","            for n in range(len(temp_bbox_x)):\n","\n","                if (math.sqrt( (float(temp_bbox_x[n]) - (predicted_centers_x[m]) )**2 + \n","                                (float(temp_bbox_y[n]) - (predicted_centers_y[m]) )**2 ) ) <= 40:\n","                                \n","\n","                    # cv2_imshow(im[int(predicted_centers_y[n]-64):int(predicted_centers_y[n]+64), int(predicted_centers_x[n]-64):int(predicted_centers_x[n]+64)])\n","                    # try:\n","                    #     cv2.imwrite('/content/train_tp/tp_'+str(true_count)+'.jpg', im[int(predicted_centers_y[m]-32):int(predicted_centers_y[m]+32), int(predicted_centers_x[m]-32):int(predicted_centers_x[m]+32)])\n","                    # except Exception as e:\n","                    #     print(e)\n","                    # true_count = true_count+1\n","                    TP += 1\n","                    break\n","                if n == ( len(temp_bbox_x)-1 ):                 \n","                    FP += 1\n","                    # cv2_imshow(im[int(predicted_centers_y[m]-64):int(predicted_centers_y[m]+64), int(predicted_centers_x[m]-64):int(predicted_centers_x[m]+64)])\n","                    try:\n","                        cv2.imwrite('/content/train_fp/fp_'+str(false_count)+'.jpg', im[int(predicted_centers_y[m]-32):int(predicted_centers_y[m]+32), int(predicted_centers_x[m]-32):int(predicted_centers_x[m]+32)])\n","                    except Exception as e:\n","                        print(e)                    \n","                    false_count = false_count+1\n","\n","print(FP)\n","print(TP)\n","print(total)\n","\n","\n","Precision = TP/(TP+FP)\n","Recall = TP/(total)\n","\n","f_score = (2 * Precision * Recall) / (Precision + Recall)\n","\n","print(Precision)\n","print(Recall)\n","print(f_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mcxj6a9LzQcP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1594199123479,"user_tz":-300,"elapsed":58165,"user":{"displayName":"ahsan mukhtar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAD6vseYp0U4rmOmtAqfN4cZKVZoQziLZpm6TPCw=s64","userId":"04596187757715530026"}},"outputId":"32894adb-3043-469f-de96-a247425485c6"},"source":["'''\n","Finding True Positive, False Negative samples in train dataset.\n","'''\n","\n","\n","from detectron2.utils.visualizer import ColorMode\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","from detectron2.structures import BoxMode\n","import math  \n","import csv\n","from tqdm import tqdm\n","\n","dataset_dicts = DatasetCatalog.get(\"cancer_test1\")\n","cancer_metadata = MetadataCatalog.get(\"cancer_test1\")\n","\n","TP = 0\n","FN = 0\n","FP = 0\n","total = 0\n","true_count = 0\n","false_count = 0\n","\n","for d in tqdm(dataset_dicts): \n","\n","        bboxs = []\n","        bbox_center_x = []\n","        bbox_center_y = []\n","\n","        predicted_centers_x = []\n","        predicted_centers_y = []\n","\n","        im = cv2.imread(d['file_name'])\n","        outputs = predictor(im)\n","\n","        for i in range(len(d['annotations'])):\n","            bboxs.append(d['annotations'][i]['bbox'])\n","\n","        total = total + len(bboxs)\n","\n","        for bbox in bboxs:\n","            bbox_center_x.append((bbox[0]+bbox[0]+bbox[2])/2)\n","            bbox_center_y.append((bbox[1]+bbox[1]+bbox[3])/2)\n","\n","        predicted_bboxs = outputs[\"instances\"].pred_boxes.to(\"cpu\").tensor.numpy()\n","        \n","        for predicted_bbox in predicted_bboxs:\n","            predicted_centers_x.append((predicted_bbox[0]+predicted_bbox[2])/2)\n","            predicted_centers_y.append((predicted_bbox[1]+predicted_bbox[3])/2)  \n","\n","        i = 0\n","        while i < len(predicted_centers_x):\n","            j = 0\n","            while j < len(predicted_centers_x):\n","                if i == j:\n","                    j += 1\n","                    pass\n","                else:\n","                    if (math.sqrt( (predicted_centers_y[j] - predicted_centers_y[i])**2 + \n","                                        (predicted_centers_x[j] - predicted_centers_x[i])**2 ) ) <= 30:\n","\n","                        predicted_centers_x = np.delete(predicted_centers_x,j)\n","                        predicted_centers_y = np.delete(predicted_centers_y,j)\n","\n","                    else:\n","                        j += 1\n","\n","            i += 1\n","\n","        temp_bbox_x = bbox_center_x\n","        temp_bbox_y = bbox_center_y\n","\n","\n","        for m in range(len(predicted_centers_x)):\n","            for n in range(len(temp_bbox_x)):\n","\n","                if (math.sqrt( (float(temp_bbox_x[n]) - (predicted_centers_x[m]) )**2 + \n","                                (float(temp_bbox_y[n]) - (predicted_centers_y[m]) )**2 ) ) <= 30:\n","                                \n","\n","                    # cv2_imshow(im[int(predicted_centers_y[n]-64):int(predicted_centers_y[n]+64), int(predicted_centers_x[n]-64):int(predicted_centers_x[n]+64)])\n","                    try:\n","                        cv2.imwrite('/content/test_tp0.2/tp_'+str(true_count)+'.jpg', im[int(predicted_centers_y[m]-32):int(predicted_centers_y[m]+32), int(predicted_centers_x[m]-32):int(predicted_centers_x[m]+32)])\n","                    except Exception as e:\n","                        print(e)\n","                    true_count = true_count+1\n","                    TP += 1\n","                    break\n","                if n == ( len(temp_bbox_x)-1 ):                 \n","                    FP += 1\n","                    # cv2_imshow(im[int(predicted_centers_y[m]-64):int(predicted_centers_y[m]+64), int(predicted_centers_x[m]-64):int(predicted_centers_x[m]+64)])\n","                    try:\n","                        cv2.imwrite('/content/test_fp0.2/fp_'+str(false_count)+'.jpg', im[int(predicted_centers_y[m]-32):int(predicted_centers_y[m]+32), int(predicted_centers_x[m]-32):int(predicted_centers_x[m]+32)])\n","                    except Exception as e:\n","                        print(e)                    \n","                    false_count = false_count+1\n","\n","print(FP)\n","print(TP)\n","print(total)\n","\n","\n","Precision = TP/(TP+FP)\n","Recall = TP/(total)\n","\n","f_score = (2 * Precision * Recall) / (Precision + Recall)\n","\n","print(Precision)\n","print(Recall)\n","print(f_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[07/08 09:04:26 d2.data.datasets.coco]: \u001b[0mLoaded 155 images in COCO format from /content/drive/My Drive/new hope/test.json\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 1/155 [00:00<01:06,  2.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 32%|███▏      | 49/155 [00:14<00:29,  3.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▉      | 61/155 [00:17<00:25,  3.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 81/155 [00:23<00:20,  3.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 155/155 [00:56<00:00,  2.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["217\n","324\n","487\n","0.5988909426987061\n","0.6652977412731006\n","0.6303501945525293\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zP7SYWmNh1VM","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}